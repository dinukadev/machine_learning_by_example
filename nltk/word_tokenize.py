from nltk.tokenize import word_tokenize

sent = '''I am reading a book.
          It is Python Machine Learning By Example,
          2nd Edition.'''

print(word_tokenize(sent))
